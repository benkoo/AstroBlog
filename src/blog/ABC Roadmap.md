---
title: "ABC Roadmap: a living process to experience learning"
pubDate: 2024-01-15T11:37:02+08:00
description: "A comprehensive guide to the ABC curriculum's approach to knowledge validation and dissemination, integrating classical education principles with modern technological solutions for coherent learning experiences."
author: "Ben Koo"
image:
  url: "/images/roadmap.jpg"
  alt: "ABC Roadmap Concept Illustration"
tags: ["ABC curriculum", "Education", "SSOT", "SOLID principles", "Learning Method"]
modified: 2025-02-05T08:23:45+08:00
subject: Learning, Education, ABC, Scientific Learning Method, Strategic Roadmap, entropy, LoM, DSL, SSoT, SOLID priniciples
authors: Ben Koo, ChatGPT, Bard, Gemini
created: 2024-01-15T11:37:02+08:00
---

# Context of ABC Roadmap

[[In a world where]] [[logic]] is no longer prioritized in decision-making, capitalists and media outlets have exacerbated [[information asymmetry]]. The rise of [[Generative AI]] ([[GAI]]) and [[LLM|LLMs]] has further intensified these challenges, exposing society to persistent threats from [[information warfare]]. To counteract these issues and reduce information asymmetry, our global community requires a new approach for validating and disseminating information—one that respects local contexts in both format and timeline while establishing a **Single Source of Truth ([[SSOT]])** to anchor coherence and trust. This article explains the over arching concepts in how [[ABC curriculum]] is designed. The detailed, lowered level organization of the roadmap, or the _theoretical compass of the intellectual roadmap_ will follow the [[SOLID principles]] and the [[Functional Roadmap]].

The **[[ABC curriculum]]** addresses this need by empowering individuals to navigate the infinite space of knowledge with purpose and clarity. By employing chunking methods, it transforms unbounded infinities into bounded rationalities, drawing foundational insights from fields such as set theory, database instruments, and topology. This structure ensures that information is not only validated but also coherent and relevant across diverse contexts.

Through the integration of an SSOT, the curriculum creates a logical framework that upholds clarity and integrity in an increasingly complex informational landscape. It provides a reliable foundation for knowledge exploration, enabling users to align their learning with logical principles while maintaining the flexibility to adapt to evolving local and global demands. By fostering coherence, relevance, and a commitment to rationality, the **ABC curriculum** serves as a vital tool for countering disinformation and building an informed, resilient society.

# Introduction to the ABC Curriculum

In response to these challenges, the **[[ABC curriculum]]** draws inspiration from classical Greek education, particularly the **[[Trivium]]** and **[[Quadrivium]]**. The Trivium—comprising **Grammar**, **Logic**, and **Rhetoric**—establishes a foundation in language and structured reasoning, while the Quadrivium—encompassing **Arithmetic**, **Geometry**, **Music**, and **Astronomy**—builds on this framework through mathematical and scientific inquiry.

While these disciplines represent high-level categories of well-known content knowledge, their true power lies in the structured relationships that connect them. The **ABC curriculum** structurally adheres to **[[Lattice Theory]]** to define **orderly relationships**, ensuring a coherent and hierarchical organization of knowledge. Additionally, it leverages **[[Number Theory]]** to manage **intricate relationships** within **namespace structures**, allowing for precise identification, modularity, and scalable expansion of concepts. By integrating these mathematical principles, the **ABC curriculum** transforms learning into an interconnected, reproducible system, where structured reasoning and computational clarity drive educational progression.

The ABC curriculum and its roadmap can also be understood through a functional lens, similar to how operating systems are analyzed. This perspective categorizes learning activities into Memory, Executing, and Networking/Copying functions, providing a structured approach for both system design and understanding. It is crucial for ABC curriculum practitioners to coherently present content knowledge in a functional orientation, guiding learners to interpret phenomena in terms of function. The emphasis on these functions as primitives is essential for students learning to build software to automate repetitive activities. The focus should be on creating a workflow-based abstraction model, where tasks are viewed as reproducible workflows rather than merely fixing syntactical errors. Understanding the input/output structural relations of functions is key to creating effective flows and enhancing the learning process.

## Unified Functional Model

The concept of a Unified Functional Model, inspired by the engineering approaches of advanced multimodal models like [[Janus-Pro]], offers a comprehensive framework for enhancing knowledge transfer in educational curricula. By integrating insights from large language models (LLMs), the ABC curriculum can leverage both textual and visual data to enrich learning experiences. This integration allows for a more dynamic and interactive learning environment, facilitating better application of knowledge in real-world contexts.

## Function-Based Abstraction and Category Theory

The ABC Roadmap is fundamentally built on a workflow-based abstraction that leverages the unifying idea of treating everything as functions. This approach follows the formalism of function composition from [[Category Theory]], which serves as our unifying theoretical framework. In Category Theory, functions (or morphisms) can be composed to create new functions, providing a rigorous mathematical foundation for understanding how different components of a system interact and combine.

The power of this approach lies in its universality: any representable system can be analyzed through the lens of functions and their compositions. Whether we're dealing with data transformations, learning processes, or system interactions, Category Theory provides the tools to reason about their compositional and analytical qualities. This theoretical foundation ensures logical coherence across the roadmap, as all components can be understood and manipulated using the same fundamental principles.

By using function composition as a core principle, the ABC Roadmap achieves several key benefits:

1. **Optimization of Reasoning:** The functional approach allows us to break down complex systems into composable units, making it easier to reason about their behavior and properties. This decomposition enables more efficient analysis and problem-solving.

2. **Timely Responses:** The clear understanding of function composition patterns helps optimize the flow of operations, enabling the system to produce timely responses for various functional services.

3. **Domain Adaptability:** The abstract nature of Category Theory allows the roadmap to relate to arbitrary domains naturally. Functions can be specialized to specific contexts while maintaining their fundamental compositional properties.

4. **Contextual Relevance:** The ability to compose functions in different ways enables the roadmap to adapt its services to specific user needs and contexts, providing relevant and engaging experiences for users and consumers.

The unifying abstraction of treating everything as functions creates a seamless integration framework where:
- Learning activities are viewed as transformations (functions) between knowledge states
- Educational resources are functions that map from concepts to understanding
- Assessment tools are functions that measure the effectiveness of these transformations
- Collaboration tools are functions that compose individual learning processes into group activities

This functional perspective ensures that the roadmap remains both theoretically sound and practically effective, making it a powerful tool for knowledge management and application in the modern digital landscape. The use of Category Theory not only provides mathematical rigor but also offers practical insights into how to structure and optimize educational workflows for maximum benefit.

## Computationally Supported by Semiotics

The **ABC curriculum** functions as a **behavioral roadmap**, utilizing **[[Content Addressable Schemes]]** in data management to organize and compress the namespace of knowledge. This approach integrates **[[Archetypal Theory|Archetypal Theories]]**, **[[Broadly Accessible Tools]]**, and **[[Contextualized Applications]]** to create a structured, sound, and comprehensive learning framework.

Drawing from the long historical tradition of **[[Mathematical Logic]]**, particularly in relation to **[[Set Theory]]** and **[[Topology]]**, this roadmap forms a foundational approach for interpreting and organizing knowledge through the lens of computational linguistics. Any roadmap serves as an abstraction for **information compression**; in this context, the ABC roadmap employs advanced data compression technologies, akin to **[[Unified Configuration Management]]** through the universal parameter of **[[time]]**. Following hermeneutic principles, it continuously reinterprets information, creating layers of meaning that adapt to evolving contexts.

The roadmap prioritizes reallocating and realigning resource configurations into a unifying metric based on **[[Entropy]]**, employing statistical tools such as **[[LDA]]** and **[[LSA]]** to maximize **[[Information Density]]** for all decision-making agents. This structured alignment enhances the clarity and effectiveness of learning pathways, leveraging computational means to support comprehension and adaptability.

If these concepts feel overwhelming, a simpler introduction is available at **[[Data-driven Project Management Skills]]**. For deeper insights into applying this roadmap, explore **[[時空緒言]]** and the **[[Strategic Roadmap]]** for a more contextual application of these principles.

# The Role of the ABC Roadmap in Knowledge Exploration

The **[[ABC Roadmap]]** serves as a foundational metadata structure, guiding individuals in navigating the vast knowledge map that is increasingly accessible through various Large Language Models (LLMs). By integrating diverse sources of public knowledge stored on personal computing devices, the roadmap enhances users' ability to access and utilize content knowledge effectively. This framework not only facilitates exploration but also empowers users to make informed decisions based on the wealth of information available at their fingertips.

As users engage with the ABC Roadmap, they can better understand the interconnectedness of knowledge domains and leverage this understanding to enhance their learning experiences. The roadmap acts as a compass, directing individuals through the complexities of information asymmetry and enabling them to harness the potential of LLMs to explore and expand their knowledge horizons. By providing a structured approach to knowledge management, the ABC Roadmap ensures that learners can navigate the digital landscape with clarity and purpose, ultimately fostering a more informed and knowledgeable society.

## Computationally supported by Semiotics

The **ABC curriculum** functions as a **behavioral roadmap**, utilizing **[[Content Addressable Schemes]]** in data management to organize and compress the namespace of knowledge. This approach integrates **[[Archetypal Theory|Archetypal Theories]]**, **[[Broadly Accessible Tools]]**, and **[[Contextualized Applications]]** to create a structured, sound, and comprehensive learning framework.

Drawing from the long historical tradition of **[[Mathematical Logic]]**, particularly in relation to **[[Set Theory]]** and **[[Topology]]**, this roadmap forms a foundational approach for interpreting and organizing knowledge through the lens of computational linguistics. Any roadmap serves as an abstraction for **information compression**; in this context, the ABC roadmap employs advanced data compression technologies, akin to **[[Unified Configuration Management]]** through the universal parameter of **[[time]]**. Following hermeneutic principles, it continuously reinterprets information, creating layers of meaning that adapt to evolving contexts.

The roadmap prioritizes reallocating and realigning resource configurations into a unifying metric based on **[[Entropy]]**, employing statistical tools such as **[[LDA]]** and **[[LSA]]** to maximize **[[Information Density]]** for all decision-making agents. This structured alignment enhances the clarity and effectiveness of learning pathways, leveraging computational means to support comprehension and adaptability.

If these concepts feel overwhelming, a simpler introduction is available at **[[Data-driven Project Management Skills]]**. For deeper insights into applying this roadmap, explore **[[時空緒言]]** and the **[[Strategic Roadmap]]** for a more contextual application of these principles.

### Personal Data as a Foundation for Learning

The existence of the **[[PKC]]** and other data collection tools provides a foundation for individuals to use personal data to guide their ideal learning trajectory. Understanding how to leverage and manage one’s existing data for future learning activities serves as the initial action. To begin this journey, start by **[[learn how to manipulate files]]**. As the generic unit of data storage, the **[[File]]** acts as a persistent mechanism to preserve **[[collective memory]]**, thereby enabling **[[reuse#Reuse in Knowledge Management|knowledge reuse]]** across time and space.

### Building Knowledge through the ABC Roadmap

As users follow the **[[ABC Roadmap]]**, we employ **[[semantic computation]]** and a **[[Content Addressable Scheme]]** to create **[[Breadcrumbs]]** (or **[[Logging]]**), enabling a layered accumulation of knowledge through the roadmap’s breadth and depth. Files of various sizes are stored using industry standards: **[[GitHub]]** for code, **[[Docker Hub]]** for OS-level images, and **[[Hugging Face]]** for Large Language Models. Together, these practices unify data across applications, ensuring scalable, persistent storage at every stage of learning and knowledge development.

In this structure, language serves not only as a communication tool but as the framework for organizing, managing, and scaling knowledge, aligning the classical foundations of [[Trivium]] and [[Quadrivium]] with modern digital learning.

### Weaving a Decentralized Web of Knowledge with libp2p

To foster a truly interconnected and resilient learning environment, the **[[ABC Roadmap]]** leverages **[[libp2p]]** as its underlying network infrastructure. This peer-to-peer network protocol empowers learners to connect and share knowledge directly, transcending the limitations of centralized platforms.

**Libp2p** facilitates a fluid and dynamic network topology, enabling:

- **Decentralized Content Distribution:** Learning resources and **[[Personal Knowledge Containers]] ([[PKC]]s)** can be hosted and accessed directly from peers, fostering resilience and censorship resistance.
- **Secure Communication:** Encrypted communication channels ensure the privacy and integrity of shared knowledge, safeguarding valuable learning assets.
- **Dynamic Knowledge Sharing:** Learners can form collaborative learning clusters, sharing insights and updates in real-time, fostering a vibrant ecosystem of knowledge exchange.
- **Seamless Integration with IPFS:** By utilizing **[[IPFS]]** as the content addressing layer, libp2p ensures efficient content retrieval and versioning, creating a robust and scalable foundation for the ABC Roadmap.

Through libp2p, the ABC Roadmap transforms into a decentralized web of knowledge, empowering learners to connect, collaborate, and contribute to a shared pool of ever-evolving insights. This fosters a resilient and accessible learning environment, where knowledge transcends geographical boundaries and thrives on the collective intelligence of its participants.

# The Tao of Learning

The core of learning can be encapsulated in a single word: **[[continuation]]**. Learning is essentially an ongoing understanding of what must be done next, continuously guiding each practitioner towards a consistent pathway, or `the enlightened way` (the **[[Tao]] -> [[道]]**). In the **ABC curriculum**, this continuation is framed as a **roadmap of actions**, based on the rule of **consistency** across both ideas and actions.

## Taos Grow on Trees

All information in this roadmap can be expressed as a **partially ordered set (POSet)** or **lattice**, simplifying complex learning pathways into an **[[Abstract Syntax Tree]] ([[AST]])** format. This mantra suggests that [[ABC Roadmap]] should be presented as a versatile, web-based user interface to convert data content into AST, similar to the **[[AST Explorer]]** application or the **[[ITrees]]** tool developed by researchers like **[[Li-Yao Xia]]**.

## Factuals and Counter Factuals

The ABC curriculum employs [[AST]] as the **universal data representation scheme** to maintain consistency in learning workflows. This scheme supports documentation of experiences, drawing both **[[factual]]** and **[[counterfactual]]** conclusions. Representing information through [[AST]] structures allows learners to see their progress as a structured [[lattice]] or [[POSet]], preserving logical consistency across each step. By aligning with the **[[Single Source of Truth]] (SSOT)** doctrine, a consistent set of filters is applied to both abstract concepts and concrete actions, ensuring integrity in behavioral assessments and data-driven insights.

### Applying the ABC Roadmap through AST

In practice, the ABC Roadmap acts as a **data-driven framework** for evaluating and planning learning activities using an [[AST]] interface. Learners can visually represent their actions, decisions, and knowledge as an evolving [[AST]], which provides a roadmap for behavior and reasoning. This [[AST-based design]] allows practitioners to break down arbitrarily complex activities into a structured, stepwise format.

## Conventions in Data Science Communities

The **ABC curriculum** emphasizes building a consistent workflow by leveraging **multi-modal large language models** for data filtering and indexing. These tools can automatically convert insights and notes into **[[AST]] representations**, offering a seamless framework for organizing knowledge. At the initial stages, learners are encouraged to capture their ideas using **[[note-taking]] technologies**. This practice addresses **[[information asymmetry]]** by creating a structured, traceable record of thought and behavior, helping learners track and build upon their understanding over time.

### Note-Taking and Information Structuring in the ABC Curriculum

The curriculum provides guidance on effective note-taking, using accessible formats such as **[[Markdown]] syntax** and **[[hyperlinks]]** to facilitate sharing and integration with automation tools. Well-organized notes contribute to personal **AST** structures that align with the broader curriculum roadmap. Over time, learners refine and publish these notes, creating shared knowledge assets. Online tutorials and resources for note-taking are abundant, allowing learners to establish structured, editable content that fits seamlessly into shared AST models, fostering collaborative learning.

### Project Template and Directory Structure with Cookiecutter

The **ABC curriculum** integrates **[[Cookiecutter]]** from [DrivenData](https://cookiecutter-data-science.drivendata.org/why/) as the core project template, establishing a standardized directory structure that streamlines project organization and enhances reproducibility. Cookiecutter provides a data science-specific project layout that ensures uniformity across projects, making it easier for team members to manage and access data assets, scripts, documentation, and other essential files.

Each project within the ABC curriculum will follow this top-level directory structure, which significantly simplifies the management of complex **[[Cross-Category Dependencies]] (CCDs)**. By explicitly organizing interdependent components across various categories—such as data processing, modeling, and evaluation—Cookiecutter enables learners to manage these dependencies effectively. The template guides students in building workflows that are modular, accessible, and adaptable to new demands, promoting best practices in data science project management.

For ABC learners, adopting [[Cookiecutter]] in their projects is not just about standardization; it provides hands-on experience with strategic organization techniques that simplify project scaling, sharing, and navigation. Cookiecutter thus plays a pivotal role in handling the intricacies of CCDs, ensuring that workflows remain cohesive and manageable as projects grow in scope and complexity. This mastery of project organization and dependency management is crucial for success in data-driven environments, making Cookiecutter a foundational tool for the [[ABC Roadmap]].

### Linguistic Approaches in Learning

The **ABC curriculum** employs Abstract Syntax Trees ([[AST]]) as a linguistic framework, grounded in **Semiotics**, **Rhetorics**, and **Hermeneutics**, to structure and navigate content across various fields systematically. Through the hierarchical AST format, information becomes logically organized, promoting an intuitive and accessible traversal of knowledge. AST-based organization enables the computational linking of insights, notes, and project components, forming a unified, navigable structure that reflects a sophisticated understanding of meaning, context, and interpretation.

This approach is reinforced by the **Cookiecutter** project structure, which provides a directory hierarchy designed to align with the [[AST]] model. This structure allows learners to identify connections and dependencies between different parts of the curriculum, creating pathways that reflect both the meaning ([[Semiotics]]) and the persuasive power ([[Rhetoric]]) of information, as well as encouraging reflective interpretation ([[Hermeneutics]]). By linking components and dependencies cohesively, the curriculum facilitates a linguistically informed learning journey, supporting effective understanding and collaboration across diverse domains.

## Web-based AST Tools Operationalize ABC Roadmap with State Management

The ABC curriculum aims to present learning in a **unified framework** that visually represents connections, hierarchies, and dependencies across topics. This is achieved through an AST-based roadmap, allowing learners to navigate complex information landscapes with clarity. This roadmap functions as a **general-purpose web-based interface** to organize and translate learning content into an AST, aiding comprehension and collaboration.

**Introducing State Management with Redux and XState**

To further enhance the roadmap's functionality and emphasize the dynamic nature of learning, the ABC Roadmap will introduce **[[Redux]]** as a state management [[design pattern]]. By leveraging Redux's vocabulary and terminology (actions, reducers, store), learners will gain a practical understanding of state management in action-oriented web applications. This will provide them with valuable skills applicable to a wide range of software development scenarios.

Later, the roadmap will incorporate **[[XState]]**, a powerful state machine and modeling tool. XState allows for more complex state management scenarios, enabling learners to model and visualize intricate workflows and transitions. This combination of Redux and XState provides a robust foundation for understanding and implementing state management in diverse contexts.

**Visualizing and Managing Evolutionary States**

By referencing tools like **[[AST Explorer]]** and **[[ITrees]]**, learners can visualize how their data fits into a broader lattice structure. This enables them to make coherent, logically aligned decisions at every stage of learning. The integration of state management tools like Redux and XState further enhances this capability by:

- **Modeling dynamic processes:** Learners can model the evolution of their understanding and the progression through the learning journey as a series of state transitions.
- **Monitoring progress:** They can track their learning progress and identify areas where they might need to revisit or reinforce concepts.
- **Managing complexity at scale:** As the learning content grows, state management tools provide a structured approach to handle increasingly complex relationships and dependencies.

Ultimately, the ABC Roadmap, empowered by web-based state management modeling and monitoring tools, helps learners better manage evolutionary states at scale. This approach fosters a deeper understanding of complex systems and equips learners with valuable skills for navigating the ever-evolving landscape of knowledge.

For further insights into how the structure of knowledge aligns with physical principles, explore **[[@MostFundamentalStructure2024|The most fundamental structure in physics]]**. The AST approach illustrates how structured learning enables efficient information processing, making the ABC curriculum an adaptable tool for building and sharing knowledge in the modern digital landscape.

## Intermission and thinking about Note-taking

Before you move onto the next stage, it is a good time to rest for a while and watch a highly informative and inclusive video about [[Note-taking]] technologies: (I also consider this video entertaining, but that is a subjective judgement.)
![](https://www.youtube.com/watch?v=XRpHIa-2XCE)

For those of you who like to study other people's notes, please take a look at how [[Stephen Wolfram]] does [[Note-taking]] in his [[@50YearQuestMy2023|A 50-Year Quest: My Personal Journey with the Second Law of Thermodynamics]].

# Implementing PKC as part of the Roadmap
See [[2025-01-20#ABC Roadmap and SDN]]

# A Single Unifying Namespace

The [[ABC curriculum]] will establish a public [[namespace]] to manage its diverse data assets. This namespace will leverage Git and GitHub for version control, ensuring both data integrity and the ability to track changes over time. It will be shared to all interested parties to build their own namespaces. Key benefits of this approach include:

- **Clear Data Separation:** Source code, configuration data, and user-owned assets will reside in three distinctly organized sections of a managed namespace, enhancing organization and maintainability.
- **Foundation for Shared Knowledge and a Bridge Between Worlds:** The unified namespace will be transformed into a dynamic set of multi-modal word embeddings. These embeddings, capturing semantic meaning in text, images, audio, and other multi-media data, establish a [[bridgelet|bridge]] between continuous and discrete representations of knowledge. They will be stored in a single, unifying vector database, forming the foundation of a shared knowledge base accessible to the entire community.
- **Semantic Power:** With the vector database as its 'neural network,' the system enables semantic queries, facilitating knowledge discovery, and unlocks innovative compositional content generation capabilities. See the following video clip: 
![[@artoftheproblemHowNeuralNetworks2023#All Perceptions are Languages]]

A unifying and [[Vector Database|vectorized]] namespace is crucial for the ABC roadmap. It offers a distinct advantage: it streamlines our operational vocabulary and makes it **computable**, grounding it in the precise language of mathematics. This helps users master the sophisticated concepts found within mathematical literature, enabling clear and precise communication. Additionally, this computable vocabulary allows large language models to accurately understand the nuanced meanings conveyed by human agents.

This shared, condensed vocabulary serves as the [[breadcrumbs]] of the ABC Roadmap, guiding users along their intellectual journey. By linking concepts to a common vectorized content base with measurable [[information density]], it ensures a faster convergence to shared understanding. This empowers users to navigate real-world knowledge complexities while developing an adaptive language strategy. Ultimately, this approach helps users cope with [[incommensurability|incommensurable terms]] over time, addressing concerns raised by both [[Plato's Problem|Plato]] and [[Orwell's Problem|Orwell]]. To learn about these ideas can be compressed into one unifying representational model in [[Linear Algebra]], see [[Quantum Sense]]'s video:[[@WhyLinearAlgebraInQuantumMechanics2023|Ch 1: Why linear algebra? | Maths of Quantum Mechanics]]. The series on the **representational strategy** of [[Quantum Mechanics]] is a necessary starting point to learn about how to reason about practically everything. [[Quantum Sense]]'s video series is a requirement for the [[ABC Roadmap]]. Before proceeding, please think about what is a [[Monoid]]. Then, watch this video: [[@PhilosophyFunctionalProgramming2018|The philosophy of (functional) programming – Attila Egri-Nagy]] and [[Notional machine]].

# The Two Way (Bidirectional) Transformations

Using [[GAI]]/[[LLMs]], we may investigate various possibilities using a common core of knowledge. These versatile technologies enable us to connect the past and the future in a bidirectional manner. Large language models, with billions of records, offer an infinite namespace for indexing and referencing data over time. Using a single namespace to manage past content and generate future possibilities creates logical "[[continuation]]" or traceable causality. It enables computational reasoning about what might happen in the future, which helps us make decisions. It also serves as a mirror, allowing us to reflect on what factors led us to where we are today. It goes both ways. To illustrate how to abstract data representation, can be bi-directionally inform and amplify performance in physical world, please see [[@PhysicsInformedMachine2024|Physics Informed Machine Learning]] by [[Steven Brunton]]. For a more theoretical treatment on this subject matter, see [[Patrick Cousot]]'s [[@cousotAbstractInterpretationUnified1977|Abstract interpretation 1977]].

The following diagram provides a graphical illustration of how bi-directional reasoning can be formalized using a computational technique called [[Abstract Interpretation]].

![[GaloisConnectionsWithCorrectness.png]]

Automating a knowledge management process entails creating future-oriented solutions and comparing performance data to historical records. By the dictionary definition of [[Knowledge]], it is the ability to trace causal relationships bidirectionally over time. A self-contained knowledge base needs to ensure content consistency by utilizing real-world and real-time data. Individuals can now afford to coperate such self-contained knowledge bases thanks to LLM and the open source community. However, utilizing [[GAI]]/[[LLM]] knowledge bases in real-world settings necessitates a different mindset and curriculum, as well as the adoption of a new type of data sharing infrastructure that can be supplemented by a collaborative network community. To protect real-world and real-time data for a diverse set of participants, tools must be scalable and adaptable to a variety of locations and operational scenarios. Without all of these conditions met by a cohesive framework that addresses both technological and operational concerns, information integrity is impossible to ensure, and learning effectiveness may suffer as a result. As a result, a [[GAI]]/[[LLM]]-inspired curriculum must run on a highly adaptable data infrastructure that evolves and develops in tandem with the curriculum. In other words, the curriculum is also a production process for developing new methods and tools for future use.

# An Integrative Program composed of Three Tracks

[[ABC curriculum]] uses the initial [[TLA|three characters]] of English language because it signifies a [[three-tracked learning program]] that is simple, and fundamental to all learning organizations. (See [[Why ABC]].) It is about enabling self-governing networked communities to survive and thrive in the modern data-driven society. It also symbolizes that this curriculum is about helping learners acquire a basic or meta-language, [[Logic Model]], that can be later expanded and tailored for any specific applications.

The ABC Curriculum employs a set of time-based rules to organize knowledge assets that include computationally represented concepts, informational content, and educational activities. It makes use of timestamps and precedence ordering information to assist users in tracking their data assets, and guides users to use popular and industrial scale version control tools to backup their data. From a content correctness viewpoint, [[ABC curriculum]] qualifies content by examining the following three properties: [[Timeliness]], [[Accountability]], and [[Observability]]. For more details of each of these properties, please click on the hyperlinks to see more explanation.

The following diagram shows the three kinds of data, timely and spatially labeled data, subjectively interpreted data, and computationally representable and manipulated data can be enumerated into eight possible different kinds of mutually validating data asset categories. 
![[HolyTrinity_TrihitaKarana.png]]

The numbers in the tri-circle diagram indicates various categories of data assets. For example region 7 is the data category that reached total consensus, and region 0 is the data category that has not yet to be defined)

| numbers correspond to the regions in the tri-circle diagram | Data Type                                                                              | Categories of Data Assets<div><br></div>                                                                        |
|:------------------------------------------------------------|:---------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------|
|                        3: Timeliness (4,6,7)<div><br></div> | Temporal (Timestamps) and Spatial Labeling                                             |                                                                             4: Subject Statement with timestamp |
|                                   1: Accountability (4,5,7) | Authentication and Authorization with Subjective Judgements                            | 5: Data content authenticated and authorized by contractually agreeable results, often known as smart contracts |
|                                    2: Observability (5,6,7) | Machine readable information content that can be manipulated using automated processes |                                                                         6: Data with blockchain-based timestamp |  

The three properties are being applied to the content and refinement criteria for all three tracks of the curriculum, namely: [[Systems Thinking]], [[Design Thinking]], and [[Computational Thinking]]. [[Computational Thinking]] is more geared toward the theoretical foundation and the operational foundation of tools and skills acquisition. [[Design Thinking]] is more aligned with the process and the interactive exploration of pragmatic opportunities in making choices. [[Systems Thinking]] is more focused on the broader picture, and the multi-scale interactions of cause and effects. The arrangement of the content is shown in a diagram below:

## Three-Layered ABC Curriculum in one diagram

To see the overall program that one will be learning, the following diagram provides a bird's eye view.

![[ABC_in_3by3.excalidraw.svg|800px]]

If you are using [[Obsidian]], click on this link to interact with the above diagram: [Interact with the original diagram](ABC_in_3by3.excalidraw). 

The nature of developing emergent learning experiences in cross-cutting learning activities is one method to portray the design philosophy of the [[ABC curriculum]]. The vertical orientation depicts the three layers of knowledge and ability that form the [[Data Plane]], [[Control Plane]], and [[Application Plane]]. According to the horizontal orientation, ABCers may begin their journey from [[Non-Digital Native]] to [[Content Creators]] to [[Self-service Agent|Self-service Agent/Agency]]. These three phases depict the various levels of maturity that individuals or organizations may attain when it comes to the usage of computational resources. ABC students may begin their education at a range of various levels of content and continue to develop and master new talents and knowledge since the ABC curriculum is designed in this cross-cutting manner.

The three levels of intellectual maturity are taught in three distinct categories of courses:
1. [[Cognitive Foundation]] ([[Design Thinking]]): The Cognitive Foundation (Design Thinking) courses provide a data-driven approach that focuses on converting observable data evidence into instruments of reason. ABCers may boost their intellectual growth by gaining a comprehensive understanding of cognitive theories at both the individual and organizational levels. Additionally, students will get information on easily accessible tools and techniques for gathering and arranging data, such as the assortment of tools provided in [[Personal Knowledge Container]] ([[PKC]]), enabling them to gradually develop their own distinctive knowledge portfolio. In order to avoid being misled by information warfare and biases caused by limited access to local knowledge, particularly propaganda spread by commercial entities and governments, it is crucial to acquire a self-reliant framework that offers the necessary theoretical basis and understanding of effective methods for verifying and analyzing data to identify inaccuracies or take advantage of opportunities. By using computable material that requires little computing resources and harnessing reusable knowledge from open-source learning management systems (LLMs), students will acquire the essential knowledge to develop an understanding of conflicting information and become conscious of [[information security]].
2. [[Computational Thinking]]: Computational Thinking is an integrated set of courses within the ABC Curriculum that combines theoretical underpinnings such as [[Category Theory]] and [[Cubical Type Theory]] with practical programming tools like as [[Coq]], [[Lean]], and [[Idris]]. (For why one must learn Type Theory, see [[@76WhyLearnTypeTheory|Why should you learn Type Theory?]]) It promotes a mentality that combines abstract problem-solving methodologies with tangible computer resources to achieve pragmatic results. The [[Personal Knowledge Container]] ([[PKC]]) supplemented this approach by assisting in the systematic management and application of relevant theoretical and applicative knowledge. Students learn to bridge the theoretical and practical divides, ensuring that their algorithms are not only useful but also [[correctness|provably correct]] and [[performance|performant in computing]], exhibiting the seamless synthesis of rigorous reasoning with inventive problem-solving. 
3. [[Industrial Frontier]] ([[Systems Thinking]]): With interactive data analytics tools and logical rigor, the Industrial Frontier thread of courses turns learners into strategic thinkers. It focuses on real-world problem solving by providing participants with sophisticated tools for data analysis and solution generation, such as Large Language Models (LLMs). These courses instill logical rigor by using LLM-backed agents to revise and recommend material alterations interactively, much like digital expert advisers committed to assisting you in synthesizing evidence and analyzing locally relevant domain-specific ideas. Every course is designed to assist students in writing an industrial analysis report using these abilities and data-intensive tools. With the authors' consent, the content of these reports will be passed on to a localized LLM training process to enhance the knowledge and data samples for continued reuse and to further polish the comprehensiveness of the LLM-based content universe.

By converging learning into these three types of courses, we aim to achieve several goals:

- **Boost knowledge reuse:** Simplify the sharing and repurposing of learning resources and tools.
- **Fuel continuous creation:** Encourage the production of readily useable and immediately absorbable content.
- **Maximize learning efficiency:** Onsite LLM training and fine-tuning optimize knowledge retention and link creation.
- **Rigorous quality control:** Ensure data content meets the highest standards through meticulous checks.

Ultimately, the ABC curriculum empowers you to climb the ladder of self-sufficiency, leaving valuable knowledge within your organization while maximizing efficiency and quality on your data journey.

# Theory, Tools, and Applications

The ABC curriculum integrates a diverse range of educational activities and resources, enabling people to engage actively in their own lives without the need of attending traditional full-time schools. It is also designed for schools to adopt [[ABC curriculum]] freely. This curriculum enables users to acquire information via partly automated daily chores, which aids in developing a habit of personal knowledge management. Theoretically, this integrated/aided method should be minimally disruptive, accommodating all individuals, rather than just depending on written materials, visual media, and other conventional instructional techniques to learn anything in a classroom-like environment. 

## Shaping theoretical foundations with Interactive feedback

By leveraging massively indexed content knowledge in Large Language Models (LLMs) with contextualized inputs, learning processes can be much more interactive. As a result, developing a theoretical framework capable of effectively describing the dynamic characteristics of this process is crucial. Animated networks of hyperlinked documents, for example, can show the topological relationships between relevant internet information in real time. The use of interactive computational tools, such as interactive [[theorem proofing assistants]] to improve students' theoretical knowledge may necessitate a shift in fundamental mathematics course delivery. This framework is based on a formal mathematical language, namely [[Category Theory]] for describing [[Open Dynamical Systems]], which uses a form of [[hyperlink]] to allow for the description of changing relationships and occurrences that go beyond static numbers and equations. One way to concretely represent this idea is the use an integration between [[Proof Assistant]] and [[Minecraft]]. See [[Proof Assistant#ABC curriculum's Conceptual Navigation Strategy]].

### From Abstract Statement to Concrete Outcomes

The basic premise is that average persons in the LLM era must learn how to ask abstract questions to derive at concrete outcomes. This conversion from abstract statements to concrete outcomes is possible if the user has a way to recognize the relevance and consistency between the statement and the LLM-generated outcomes, over time, and bidirectionally. The bidirectional connections between the pragmatically useful outcome, and the abstractly stated requires can be shown in the following diagram, and the general wisdom is that the [[correctness]] of such bidirectional mapping can only be [[Abstract Interpretation|approximated iteratively]]:
![[GaloisConnectionsWithCorrectness.png]]

### Traditional Knowledge Management: Fragmented and Limited

Imagine trying to understand a complex topic like astrophysics by attending scattered lectures and labs, each offering a single, isolated puzzle piece. It's like blind people encountering an elephant, each grasping a different part but unable to perceive the whole magnificent creature. This is how knowledge acquisition often feels without the help of LLMs. Professionals dealing with real-world data applications are left piecing together fragmented information, struggling to see the bigger picture.

### LLMs: Converging to a Living Knowledge Tree

Knowledge management using Large Language Models (LLMs) challenges many widely held beliefs. They are similar to digitally simulated neural networks and massive living dictionaries, such as the [[Tree-of-Life]] or [[Eywa]] in the film Avatar, which serves as a single, [[universality|unifying entity]] that interconnects and sustains a vast ecosystem. Acquiring complex knowledge becomes a collaborative effort within a knowledge management community powered by LLM. Instead of stumbling around in the dark, everyone can access timely and context-sensitive answers by "plugging in" to a shared knowledge repository. Surprisingly, this tree is no longer a theoretical construct; it is now part of our publicly accessible data infrastructure. This "Tree-of-Life" is now available to a large number of people who do not understand the theoretical principles underlying it. The theoretical components of the ABC curriculum specifically target these principles and use LLM technology to localize real-world applications, reminding users of the principles and patterns that are routinely present in the applications that surround them in their daily lives. Prior to the LLM era, there was simply no incentive to gain a theoretical understanding of [[universality]] nor are average citizens interested the rules of data abstraction. It is only due to the practical usefulness of LLM that average people would need a **new way to count beyond just numbers**. Learning the fundamental logic of computation as a new form of aptitude for the industrial age is practically essential at this time, as it can assist individuals in expanding their use of LLM applications for their own benefit and improving the operational efficiencies of their organizations. The individualized nature of LLM interactions facilitates an educational and pedagogical encounter that contextualizes theoretical principles, eliciting in its users a heightened level of consciousness that extends beyond simply completing final answers.

### Community-Driven Growth and Reproducibility

Training or finetuning LLMs, like caring for the Tree of Life, has the potential to become a properly regulated community effort. Individuals can construct a data repository that is constantly evolving and contains real-world applications that serve as easily publishable case studies with the assistance of LLMs. Technical facts and figures would not be the only things included in this shared body of knowledge. Engagement with the [[Open Source Community]], as well as the governing rules for determining content ownership and using networked tools for conflict resolution (the use of smart contracts), would all be critical theoretical and operational knowledge to teach in this data-intensive world. Localized LLM's data content may encompass not only technical facts, but also social and cultural considerations, perspectives from multiple languages, and even artistic expressions. The coexistence of LLM necessitates a new theoretical framework and a matching curriculum to help people see the benefits and risks of using such a powerful data-driven tool.

### The Promise of LLMs: A Holistic Future of Computable Knowledge

LLMs are living knowledge canvasses, not endless libraries. The curriculum begins with the universal component of Category Theory's "arrow" as the single type of primitive used to construct the web of knowledge to ensure consistency. Like [[hyperlinks]], this arrow primitive connects ideas, encodes relations, and formalizes recorded knowledge. The ABC curriculum views knowledge as a tapestry rather than a collection of fragments, using [[Category Theory]] as the theoretical foundation (rather than numerical numbers as the representational basis for starters) and teaching it with the help of [[LLMs]]. As Category Theorists frequently state, learning Category Theory necessitates a large number of examples, and LLM is an excellent tool for managing a large number of examples. The curriculum's theoretical content is based on this common language of connection, which allows us to integrate the teaching of programming tools, specifically automatic proof assistant languages such as [[OCaml]], [[Coq]], and [[Lean]], as well as other data-intensive instruments such as database technologies and [[microservice|microservices]]/[[mesh network|mesh networks]]. These resources assist students in navigating the vast content landscape and weaving an ever-expanding theoretical tapestry of understanding LLMs as transformational tools with many evolving applications.

## Three-layered Namespace Management

Given the risks of confused terms and hallucinating answers in general-purpose Large Language Models, a method that prevents namespace confusion while lowering term incommensurability is required. Practitioners of the [[ABC curriculum]] will work together to administer a single set of terminology that includes both concrete technology and fast-expanding theoretical conceptions. Beginning with [[Software-defined Networking]]([[SDN]]), [[Distributed Operating Systems]], and [[Open Dynamical Systems]], a series of hyperlinked documents will delineate the dynamic content from concrete to abstract by cross-referencing terms and grounding these terms in established bodies of knowledge. This layered content architecture is used by the [[ABC curriculum]] to regulate a stable vocabulary for human communication.

## ABC's Tool Architecture through the SDN lens

Embracing the ABC curriculum demands a robust and adaptable foundation, akin to a smoothly interconnected network of computing tools. But how do we operate this intricate apparatus? Presenting knowledge about a global, ever-evolving network – where updates flow freely from a vast open-source community – requires a sophisticated language. Welcome to **Software-Defined Networking ([[SDN]])**, an elegant framework for deconstructing and managing such omnipresent computing systems.

To navigate the ABC's inner workings, we borrow from the established terminology of SDN, its tools becoming the keys to operating our collaborative learning platform. Furthermore, we draw inspiration from the rich knowledge base within the SDN community, leveraging its vocabulary to guide ABCers through this dynamic field. (Think of it as applying [[John Day]]'s "[[@PatternsNetworkArchitecture2008|Patterns in network architecture: a return to fundamentals]]" to the unique landscape of the ABC.)

To illustrate this connection, imagine the following diagram, adapted from Wikipedia's depiction of [[SDN]]. Think of each element as a crucial component of the ABC, interconnected and collaborating to empower collective learning.
![[SDN_Three_Layers.excalidraw.svg|800px]]

The three layers of [[SDN]] are known as the [[Application Plane]], [[Control Plane]], and [[Data Plane]]. These three layers classify the functional aspects of a data-intensive system, which is a feature of any real-world system that uses Large Language Model technologies. Language model size influences how quickly these systems can be updated, as well as how well they can be programmed and monitored for unusual behavior. The motto of SDN states, that any system, no matter how large or small, should be studied in terms of timeliness, programmable accountability, and behavioral observability. The ABC curriculum will teach students how to use formalized languages and tools to represent and simulate the dynamics of interactive systems, model accountable resource allocation scenarios, and strategize for real-time observability using open-source instrumentation. 

## Multimodal Tools for Knowledge Management

The ABC curriculum aims to transform learning into a vibrant, interconnected ecosystem. Building this ecosystem requires a robust set of knowledge management tools, acting as the building blocks for collaborative understanding and individual growth. Here are some essential tools to consider:

**Personal Knowledge Containers (PKCs):**

- **Concept:** Imagine a personal vault for your learning, where insights and connections are captured with the power of arrows (causal relationships). Think of hyperlinks leading to relevant resources, transclusions bringing in crucial snippets, and notes woven into a tapestry of understanding.
- **Tools:** Explore tools like Zettelkasten methodologies, digital gardens, and note-taking applications with [[Local-first Principle]] that allow for flexible linking, tagging, and organization. Platforms like [[Obsidian]], [[Dendron]], [[LogSeq]], and [[Zotero]] can be valuable starting points.
- **Functional Content:** Modularized software deployment platform [[PKC]] minimizes software deployment complexity and data collection costs. Its self-sufficient data collection, storage, and processing features greatly lower the cost of obtaining learning data for personal feedback, which was previously challenging. Providing a personalized data analytic service greatly increases the likelihood of individuals receiving valuable learning advice.

**Hyperlinked and Collaborative Knowledge Bases:**

- **Concept:** Leverage the power of hyperlinks and arrows to build shared spaces for knowledge creation and curation. MediaWiki, the engine behind Wikipedia, provides a simple but powerful framework for weaving interconnected knowledge bases.
- **Tools:** Encourage students to contribute to existing open-source knowledge bases like Wikipedia, or establish class-specific wikis to document shared learning journeys. Explore tools like TikiWiki or DokuWiki for more customizable options. It will also employ the data navigation and visualization techniques like [[knowledge graph]] and time-based data logging tools such as Blockchain and [[Grafana]]/[[Prometheus]] to enable [[Timeliness|time-based]] [[Observability]].

**Large Language Models (LLMs) and Tokenized Landscapes:**

- **Concept:** LLMs process information through a lens of tokens and multi-dimensional arrow relationships. Learning to navigate this space enables reasoning across massive datasets and opens doors to collaborative data curation.
- **Tools:** Introduce open-source LLM platforms like Hugging Face or Gradio to familiarize students with tokenization and LLM reasoning. Encourage exploration of existing datasets and participation in community projects for real-world experience. Employ interactive visualization tools like [[Lens-like Automata]] to explore the landscape of interacting data-carrying elements. See [[Lenia]]. ![](https://www.youtube.com/watch?v=AP3zeHyWakw)

**Configuration Management (CM) and DevOps Practices:**

- **Concept:** Treat the ABC ecosystem as a living system, constantly evolving and adapting. CM tools handle updates and orchestrate deployments at scale, ensuring consistency and reproducibility.
- **Tools:** Introduce students to tools like [[Git]], [[IPFS]], [[Terraform]], or [[Ansible]] to learn infrastructure management. Integrate CM practices into curriculum projects, showcasing the importance of collaboration and open-source solutions.

### Equip Logical Thinking with Logic Model

The following diagram shows how [[Logic Model]] sits in the middle of all the above mentioned tools to serve as the **[[Control Plane]]** of all data content. 

![[Bridgelet_Implementation.excalidraw.svg|800px]]

The ABC curriculum uses the Logic Model as an interface to configure and hence experiment with the computer network by controlling all data content via a unified control plane, the Logic Model. Because it uses eBPF programming interfaces instead of traditional programming languages, the Logic Model can be considered a no-code user interface for mobilizing networked computing resources at near-native speed, as shown in the bottom center of the diagram above.

The inclusion of kernel programming in the ABC curriculum highlights the idea of timeliness. By accessing low-level operating system interfaces, we may get a physics-based or hardware-based data representation, enabling us to squeeze out performance wherever it is necessary. [[Grafana]] and [[Prometheus]], as well as [[Istio]] and [[Kubernetes]], were selected as components of the design because they are open-source implementations of providing users with real-time system-level data reporting, hence offering time-based observability that works for all applications. We also promote the adoption of the notion of [[@PurelyFunctionalSoftware2006|The Purely Functional Software Deployment Model]] by packaging our software using [[Nixpkgs]] to enforce [[reproducibility]] in the overall [[MLOps]] workflow. In the illustration, the [[Keycloak]] icon depicts an open-source implementation for authentication and authorization services that may be hosted by any institution that chooses to use ABC curriculum, giving a data trail for accountability. This image effectively illustrates the programming element of the [[Personal Knowledge Container]] ([[PKC]]), the [[ABC curriculum]]'s reference implementation for data asset management tool chain.

This section provides an overview of how the ABC curriculum-recommended tool stack improves data-centric learning and optimizes the benefits of using LLM. This tool stack might be seen as an approximation of [[John Henry Newman]]'s objective of achieving universal inclusion of subject knowledge. The system endeavors to use open source technologies wherever feasible. It considers each piece of information as a unit that adheres to the file abstraction, facilitating the tracking of modifications using widely-used version control systems and sharing via ordinary file copying procedures. Additionally, it attempts to use the mechanics of hyperlinked documents inside the language definition of the Logic Model. An openly accessible curriculum should function as a dynamic repository of knowledge, enabling individuals to freely exchange and reuse the abstract framework of cause-and-effect relationships. Additionally, it incorporates [[eBPF]] to facilitate kernel programming access, enabling all participants to reach the deepest layers of computational resources and so harness the utmost amount of performance that computers can provide.

## Applications based on localized Data Configurations

When confronted with a diverse collection of domain-specific applications, ABCers equipped with an SDN-based toolbox need just alter domain-specific LLM data, a process known as fine-tuning or retraining, rather than building a comprehensive stack of data asset management tools. The emphasis on transparency in theoretical methods, industry-standard compatible toolstack (SDN-based architecture), and reproducibility advocated by [[@PurelyFunctionalSoftware2006|The Purely Functional Software Deployment Model]] that treats data content as a first-class asset in the [[ABC curriculum]] should benefit stakeholders of specific applications. Applications with stakeholders operating within learning communities that practice the [[ABC curriculum]] can form a networked community to challenge and refine the theoretical foundation, the tool stack composition that makes up the Software-Defined Networking (SDN) architecture, and propose new approaches that allow first-of-their-kind domain-specific applications to leverage prior knowledge collected by the community, as well as knowledge inferred and regen The following illustrates why the [[ABC curriculum]] is designed primarily to improve learning during the LLM era:

### Shared SDN-based Toolchest

- **Universal Language:** SDN provides a common vocabulary of tools and principles, like arrows representing connections and flows. This shared language is modeled in [[Logic Model]] as its human-machine frontend and is also compatible with the [[Behavior-driven development]] ([[BDD]]). This unification eliminates the need for siloed solutions for each application and fosters cross-domain collaboration.
- **Scalability and Adaptability:** The adaptable nature of SDN caters to the unique demands of different applications. Whether it's managing a small online course or a complex scientific database, the underlying infrastructure can scale and adapt accordingly.
- **Open-Source Collaboration:** Just like the internet itself, the ABC ecosystem thrives on open-source principles. By sharing the SDN framework and tools, communities can learn from each other's experiences and build upon shared knowledge.

### LLMs: Tailored Power for Diverse Needs

- **Domain-Specific Models:** While the SDN framework provides a common ground, applications can leverage different versions of LLMs tailored to their specific domains. An LLM trained on medical data will excel in healthcare applications, while one trained on financial data will shine in economic simulations.
- **Transfer Learning and Shared Insights:** The beauty of LLMs lies in their ability to transfer knowledge across domains. Test data from one application can be used to refine similar but different applications, enriching the entire ecosystem. For example, data from a language learning LLM can be used to improve an LLM focused on historical analysis.
- **Collaborative Exploration and Innovation:** By exposing learners to different LLM implementations, the ABC curriculum encourages cross-domain exploration and innovation. Students can see how the same basic building blocks – the SDN framework and LLM principles – can be applied to solve diverse problems, sparking creative solutions and collaborations.

### Configuration Management (CM) and tacit knowledge

The inherent capacity to detect logical anomalies in large collections of data comes from chasing the causal relational arrows articulated in [[Category Theory]]. By embracing the notion that everything can be represented as arrows and optimizing your own set of arrows, [[configuration management]] essentially revolves around this concept. Consequently, only with automated tools that can systematically capture the inherent causal arrows, store them reliably, and process them into LLMs at a low cost, we may benefit from reasoning by chasing arrows. This implies a technical challenge to effectively managing a vast collection of arrows throughout the life cycles of all arrows (causal relations). This is what recent integration between [[note-taking tools]] and [[LLM]]/[[Generative AI]] is changing life-cycles of personal data, even shifting the paradigm of [[Personal Knowledge Management]]. This data-centric platform, partially addresses [[Michael Polanyi]]'s concern of [[tacit]] knowledge.

# A Recursive Process for Refining Knowledge

Prior experience in launching and running educational programs tells me that students learn best if they are teaching others themselves. ABC curriculum as a program should be a [[Galois connections|bidirectional]] program that transforms the students while having students transform the teaching method as active feedback providers. This was the original idea that created [[XLP]], short for [[Extreme Learning Process]]. The idea is to have students who have taken the course ([[Challenge Designer|Mission Designers]]) after having some experience of the course, design challenging tasks to entice and filter other students to take on the courses they think relevant. That means, they may ask the incoming students to take on areas of content knowledge or skills that are not directly covered in the course. This will enable students and instructors to incorporate their contextualized learning motivation with the content knowledge at hand. See [[Process and Participating Model for ABC curriculum]].

As the diagram shown below, students who are taking a course on [[Computational Thinking]], might be also taking courses in Industrial Frontier and other Domain-specific courses, say Urban Design or Manufacturing. All these courses could leverage the same set of cloud-based data management technologies, as shown in the bottom layer of the diagram. The shared data infrastructure would been repeatedly practiced and used by all students while improving the functionality and accumulate content, the arrival of LLM technologies allows us to perform data mining tasks, and identify patterns of relations that were hidden in the data.
![[FirstGen_XLP_Curriculum.png]]

The coordination amongst students are grounded in the [[Logic Models]] they created to engage participation with others. [[Logic Model]] is effectively a [[Behavioral-based Design]] ([[BDD]]) style programming language that allows its users to encode knowledge content in a form that captures knowledge content in a form that can be automatically version-checked, manipulated, and hyperlinked, or transcluded into web pages that are accessible to its targeted audience. The purpose of this [[PKC]]-power process is to consolidate data management tasks into a single, open-sourced data service platform, while allowing any group to operate their own servers, but sharing a portion of their chosen data to help improve the overall data processing and knowledge accumulation eco-system. The process is base on a common and therefore converging workflow, that looks like [[DevOps]] or [[MLOps]]. For more detailed process description, see [[The Eight Stages]]. Note the interconnectedness of the eight stages are logically entangled like a [[Lattice]].
![[TriVennDiagramAsLattice.excalidraw.svg|800px]]

Go to the [[TriVennDiagramAsLattice.excalidraw|diagram]]

For more detailed process model description, see [[Paradigm shifting Nature of ABC Curriculum]].

The reader should be aware that the ABC curriculum, which has been documented as a collection of local content, may be iteratively revised utilizing [[The Eight Stages]] of content refinement activities to enhance its content. Furthermore, each step of the process may be partly or totally automated by employing a stage-specific LLM to do content refining and testing activities (See [[AutoGen]], [[Literature/PKM/Tools/Open Source/Langchain]], and [[TaskWeaver]]). This LLM-assisted approach is projected to greatly expedite the processes that can be automated and, more crucially, capture the prospects for change with quicker reaction time and understanding. In principle, this sort of procedure would increase the quality of process output, and the proofs could be confirmed in the data acquired.

# Distinct Features of ABC curriculum

The distinct features of ABC curriculum in contrast to traditional school curricula are:
1. A logically rigorous approach to reason about [[correctness]] with [[universality]] in mind.
2. All processes should be subsumed through a unifying decision model, known as the [[Logic Model]].
3. Conduct [[Namespace Management]] practice using industrial standards [[Content Addressable Scheme]], in terms of [[time]]. So that computational services are based on [[@PurelyFunctionalSoftware2006|The Purely Functional Software Deployment Model]], which is also known as the state-of-the-art in [[Configuration Management]].
4. Study the [[Game of Life]], and [[Go]], not only as a game, but an interactive form of [[Configuration Management]]. Modeling systems in Game of Life form, or Cellular Automata is different from traditional coding, because Generative AI technologies is making coding skills obsolete. See [[@officialAIGoingMake2023|AI is Going to Make Programming Obsolete 😭]]. The modern data management approach should focus on configuration management, not coding. Think of phenomenon as compressible causal relations, not as source code artifacts. This will facilitate the acquisition of type theoretic logical reasoning skills. This mental model can be visualized in terms of [[Algebraic Topology]] formalism, which can be expressed as interacting decision kernels like [[cellular automata]].
5. Use [[Lens-like Automata]] ([[Lenia]]) as the Visualization front end to engage users with the mindset of [[Configuration Management]] in Spacetime, by incorporating other time-based kernel interaction data, such as [[Kubernetes]], and use visualization tools, including [[Grafana]] and [[Prometheus]] to observe their time-based behavior properties of practical data serving clusters at scale.
6. Always pay attention to the logical void, or empty set as the source of everything representable. This idea should be grounded in [[Computational Type Theory]]. Use [[Automated Theorem Prover]] and reference [[The Little Series]] to study type theory computationally.

## Why it must be an open-sourced curriculum?

Generative AI has the ability to alter the present knowledge environment by removing inflexible and uncompromising curriculum. ABC wholeheartedly accepts and embraces this difficult situation, understanding that the difficulties cannot be adequately resolved alone via a technology solution or as a product. Moreover, it cannot be categorized as a constraining methodology, nor can it be rectified with a limited institutional provision. The origin of this must arise from an innate inclination to gain information and to adjust oneself, irrespective of whether that one is an individual or a collective entity. The ABC curriculum utilizes an inclusive approach by offering a flexible learning framework that may be used and adjusted by individuals or independent groups seeking to acquire knowledge enhanced with computational approaches. The answer can only be discovered inside a **widely distributed open-source curriculum** that acts as a standardized guideline, particularly created to be driven by data.

# Conclusion

The creation of [[ABC curriculum]] is about creating a self-sufficient knowledge dissemination and conservation model that works in the era of [[LLM]]. It focuses on the [[Timeliness]], [[Accountability]], and [[Observability]] of personalized knowledge management processes, so that individuals and small organizations can have an interactive learning experience with adequate data collection and privacy protection mechanisms. The content knowledge is organized to ensure people will have the proper foundations to become aware of their data privacy on a personal level, and it also publishes an inclusive governance model and supporting technologies to keep content knowledge up to date on a social level. It is a public model to invite learners of all kinds to participate in the sharing and refinement of knowledge with a globally-scale operational model with minimal entry barriers.

## Decision-making in the age of GAI

The curriculum is about enabling people to use computationally supported tools to organize their content knowledge and make decisions within this highly interconnected networked society. The curriculum includes in-depth computational logic content but is **NOT** about teaching people how to become programmers (See [[Edsger Wybe Dijkstra|Dijkstra]]'s work on teaching computing science [[@CrueltyReallyTeaching2022|On the Cruelty of Really Teaching Computer Science]]). It aims at developing the reasoning powers of individuals and participating organizations to apply a generally applicable set of logical reasoning methods and computing tools to practical problems that fit their local contexts. It promotes the use of LLMs and networked computing technologies to support interactive learning activities such as languages, arts, sports, sciences, and cultural activities that used to require intense time investment in qualified instructors. 

## Map to GIS Learning as a Learning Roadmap

A roadmap for studying **[[Spatial Data Science]]** or **[[Geographic Information Systems]] ([[GIS]])** serves as an ideal foundation for organizing and exploring content knowledge across various fields, given its comprehensive approach to data analysis, visualization, and spatial relationships. [[GIS]] technology offers a powerful framework for managing complex datasets and uncovering connections between seemingly unrelated information, making it relevant not only to geography and spatial studies but also to disciplines like history, social sciences, and astronomy. The tools and data types used in [[GIS]]—including layered mapping, spatial analysis, and data integration—can be transferred across these fields, allowing students and researchers to visually organize information, analyze patterns, and address real-world challenges.

Using **Abstract Syntax Trees ([[AST]])**, these diverse content structures can be systematically organized and navigated, where the hierarchical arrangement of content is calculated through algorithms such as **[[LDA]]** and **[[LSA]]**. By starting with **[[GIS]]**, learners establish a modern, versatile framework for structuring and understanding knowledge, applicable across a broad range of domains, with **AST-based** navigation as a scalable, computational foundation.

![](https://www.youtube.com/watch?v=n9dDsYLIx1c)

See [[@HowWouldLearnGIS2022|How I Would Learn GIS (If I Had To Start Over)]]

# References
```dataview 
Table title as Title, authors as Authors
where contains(subject, "ABC Roadmap") or contains(subject, "Physics Informed Machine Learning") or contains(subject, "Meta Theory")

```
